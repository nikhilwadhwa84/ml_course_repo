ggnn:
  embed_dim: 128
  hidden_dim: 128
  time_steps: [3, 1, 3, 1]
  residuals:
    1: [0]
    3: [0, 1]
comment:
  hidden_dim: 512
training:
  num_epochs: 10
  print_freq: 10
  lr: 0.001
data:
  max_batch_size: 5000
  max_graph_size: 1000
  vocab_cutoff: 10
  split_tokens: true